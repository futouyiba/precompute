{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c534e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6baea6",
   "metadata": {},
   "source": [
    "### 链条式找配置，并组装紧密数组（每张地图只需做一次，可用于生成一串派生环境场）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载 9 个地图配置，其中 6 个有 assetId\n",
      "assetId -> map_id 映射: {'1001001': 1001, '1002001': 1002, '1003001': 1003, '1004001': 1004, '1004002': 1008, '1006001': 1009}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "数据处理步骤 (Metaphysical Data Processing Steps):\n",
    "\n",
    "1.  **数据源与目标确立 (Source & Target Definition)**\n",
    "    - Source: 位于 `precompute/data` 下的静态配置表 (JSON)，定义了游戏世界的逻辑结构。\n",
    "    - Target: 位于 `ExportedData` 下的 Numpy 数组，代表了具体场景的物理数据 (Voxel/Grid)。\n",
    "\n",
    "2.  **标识符提取 (Identifier Extraction)**\n",
    "    - 从物理数据的文件名/路径中提取关键标识符 (SceneID / AssetID)。\n",
    "    - 例如: 从 `Fishing_1006001_Global.npy` 提取 `1006001`。\n",
    "\n",
    "3.  **逻辑映射建立 (Logical Mapping)**\n",
    "    - 利用中间件/配置表 (`map_scene.json`) 将物理标识符 (AssetID) 映射回系统逻辑标识符 (MapID)。\n",
    "    - 这一步是连接“即时演算数据”与“策划配置数据”的关键桥梁。\n",
    "\n",
    "4.  **上下文关联与整合 (Context Association & Integration)**\n",
    "    - 以 MapID 为锚点，级联查询关联的 Pond, Stock, Fish 配置。\n",
    "    - 将分散的数据整合为适合并行计算的结构化格式 (Numpy/Pandas)。\n",
    "\"\"\"\n",
    "\n",
    "# 配置路径\n",
    "DATA_ROOT = Path(r'D:\\fishinggame\\precompute\\data\\1\\1001')\n",
    "EXPORTED_DATA_ROOT = Path(r'D:\\fishinggame\\ExportedData')\n",
    "\n",
    "# 加载 map_scene.json\n",
    "with open(DATA_ROOT / 'map_scene.json', 'r', encoding='utf-8') as f:\n",
    "    map_scene = json.load(f)\n",
    "\n",
    "# 建立 assetId -> map_id 的反向索引\n",
    "asset_to_map = {info['assetId']: int(map_id) for map_id, info in map_scene.items() if info.get('assetId')}\n",
    "print(f'已加载 {len(map_scene)} 个地图配置，其中 {len(asset_to_map)} 个有 assetId')\n",
    "print(f'assetId -> map_id 映射: {asset_to_map}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "scene_id_lookup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件路径: D:\\fishinggame\\ExportedData\\Fishing_1006001_Dense_20260107_154037\\Fishing_1006001_Global.npy\n",
      "提取的 scene_id: 1006001\n",
      "对应的 map_id: 1009\n",
      "地图信息: {'id': 1009, 'name': 'map_base_6', 'desc': 106, 'assetId': '1006001', 'originOffsetX': 0, 'originOffsetY': 0, 'offsetX': 0, 'offsetY': 0, 'sizeX': 1000, 'sizeY': 1000, 'rotate': 0, 'mark': ''}\n"
     ]
    }
   ],
   "source": [
    "def get_scene_id_from_path(npy_path: str) -> str:\n",
    "    \"\"\"从npy文件路径中提取scene_id (如 Fishing_1006001_Global.npy -> '1006001')\"\"\"\n",
    "    match = re.search(r'Fishing_(\\d+)', str(npy_path))\n",
    "    if not match:\n",
    "        raise ValueError(f'无法从路径中提取scene_id: {npy_path}')\n",
    "    return match.group(1)\n",
    "\n",
    "def get_map_id_from_scene_id(scene_id: str) -> int:\n",
    "    \"\"\"根据scene_id查找对应的map_id\"\"\"\n",
    "    if scene_id in asset_to_map:\n",
    "        return asset_to_map[scene_id]\n",
    "    raise ValueError(f'找不到scene_id {scene_id} 对应的map_id')\n",
    "\n",
    "def get_map_id_from_npy_path(npy_path: str) -> int:\n",
    "    \"\"\"从npy文件路径直接获取map_id\"\"\"\n",
    "    scene_id = get_scene_id_from_path(npy_path)\n",
    "    return get_map_id_from_scene_id(scene_id)\n",
    "\n",
    "# 测试示例\n",
    "test_path = r'D:\\fishinggame\\ExportedData\\Fishing_1006001_Dense_20260107_154037\\Fishing_1006001_Global.npy'\n",
    "scene_id = get_scene_id_from_path(test_path)\n",
    "map_id = get_map_id_from_scene_id(scene_id)\n",
    "print(f'文件路径: {test_path}')\n",
    "print(f'提取的 scene_id: {scene_id}')\n",
    "print(f'对应的 map_id: {map_id}')\n",
    "print(f'地图信息: {map_scene[str(map_id)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a94c6",
   "metadata": {},
   "source": [
    "#### 对于局部池取stock\n",
    "* \n",
    "* 去D:\\fishinggame\\precompute\\data\\1\\1001\\fish_stock.json当中，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326ea7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载 7 个鱼塘配置\n",
      "已加载 6 个 Stock 配置\n",
      "\n",
      "当前地图: map_base_6 (ID: 1009)\n",
      "关联的 Desc ID (用于对应 fish_pond_list.mapId): 106\n",
      "\n",
      "查找 mapId == 106 的鱼塘...\n",
      "找到 1 个关联鱼塘:\n",
      "  - Pond: Sunset_Stream (ID: 301020005) -> Stock ID: 301030106\n",
      "    Stock 详情: Name=stock_sunset, ResetTime=05:00\n"
     ]
    }
   ],
   "source": [
    "# 加载额外的配置表\n",
    "with open(DATA_ROOT / 'fish_pond_list.json', 'r', encoding='utf-8') as f:\n",
    "    fish_pond_list = json.load(f)\n",
    "\n",
    "with open(DATA_ROOT / 'fish_stock.json', 'r', encoding='utf-8') as f:\n",
    "    fish_stock_config = json.load(f)\n",
    "\n",
    "print(f\"已加载 {len(fish_pond_list)} 个鱼塘配置\")\n",
    "print(f\"已加载 {len(fish_stock_config)} 个 Stock 配置\")\n",
    "\n",
    "# 获取 map_id 对应的 map_scene 配置\n",
    "current_map_info = map_scene.get(str(map_id))\n",
    "if not current_map_info:\n",
    "    raise ValueError(f\"Found no map info for id {map_id}\")\n",
    "\n",
    "map_desc_id = current_map_info.get('desc')\n",
    "print(f\"\\n当前地图: {current_map_info['name']} (ID: {map_id})\")\n",
    "print(f\"关联的 Desc ID (用于对应 fish_pond_list.mapId): {map_desc_id}\")\n",
    "\n",
    "# 查找关联的 Pond 和 Stock\n",
    "print(f\"\\n查找 mapId == {map_desc_id} 的鱼塘...\")\n",
    "related_ponds = [pond for pond in fish_pond_list.values() if pond.get('mapId') == map_desc_id]\n",
    "\n",
    "if not related_ponds:\n",
    "    print(\"警告: 未找到关联的鱼塘配置 (Pond)\")\n",
    "else:\n",
    "    print(f\"找到 {len(related_ponds)} 个关联鱼塘:\")\n",
    "    for pond in related_ponds:\n",
    "        # 兼容处理: 有些json key可能是str类型的id\n",
    "        pond_id = pond.get('id')\n",
    "        pond_name = pond.get('name')\n",
    "        stock_id = pond.get('fishStockId')\n",
    "        \n",
    "        print(f\"  - Pond: {pond_name} (ID: {pond_id}) -> Stock ID: {stock_id}\")\n",
    "        \n",
    "        # 查询 Stock 详情 (注意 key 可能是字符串)\n",
    "        stock_info = fish_stock_config.get(str(stock_id))\n",
    "        if stock_info:\n",
    "             print(f\"    Stock 详情: Name={stock_info.get('name')}, ResetTime={stock_info.get('resetDayTime')}\")\n",
    "        else:\n",
    "             print(f\"    警告: 在 fish_stock.json 中未找到 Stock ID {stock_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a062d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顺着往下进行数据查找和组装numpy，供后面的计算使用。\n",
    "# 大致思路为：\n",
    "# 5. 遍历 Stock ID (Stock -> Release)：\n",
    "#    - 从相关联的池塘中提取 Stock ID，查找其下属的所有 Release ID。\n",
    "# 6. Eager Loading (Release -> Fish/Env):\n",
    "#    - 对每个 Release ID，立即提取所需的全部配置信息，包括：\n",
    "#      - 基础属性: qualityId (即原 fishId), weight/length ranges (min/max).\n",
    "#      - 关键系数: minEnvCoeff, minAdaptCoeff.\n",
    "#      - 关联元数据: speciesId, envAffinityId (即原 envId).\n",
    "# 7. 组装 DataFrame (Assembly):\n",
    "#    - 将上述所有提取的字段扁平化，组装成 Pandas DataFrame (`stockFishesPd`)。\n",
    "#    - 每一行代表一个 Release 配置，为后续的概率计算和环境场生成做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf363e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Release and Quality configs...\n",
      "Configs loaded.\n",
      "Processing 1 unique Stock IDs associated with the current map.\n",
      "Created stockFishesPd with 35 rows.\n",
      "     stockId  releaseId  qualityId  envAffinityId  speciesId  weight_min  weight_max  len_min  len_max  minEnvCoeff  minAdaptCoeff                                name  probWeight\n",
      "0  301030106     300500  101034430        1013390  101020063         150         450       26       37            0              0  Release_American_Shad_Young_sunset      250000\n",
      "1  301030106     300510  101034090        1013050  101020010          50         200       16       26            0              0    Release_Brook_Trout_Young_sunset      100000\n",
      "2  301030106     300520  101031007        1010066  101020010         200         350       26       32            0              0   Release_Brook_Trout_Common_sunset      100000\n",
      "3  301030106     300530  101034450        1013410  101020003         150         450       28       40            0              0         Release_Bowfin_Young_sunset      200000\n",
      "4  301030106     300540  101034510        1013470  101020050         550         700       37       40            0              0       Release_Hardhead_Young_sunset       17928\n",
      "\n",
      "Column Types:\n",
      "stockId           int64\n",
      "releaseId         int64\n",
      "qualityId         int64\n",
      "envAffinityId     int64\n",
      "speciesId         int64\n",
      "weight_min        int64\n",
      "weight_max        int64\n",
      "len_min           int64\n",
      "len_max           int64\n",
      "minEnvCoeff       int64\n",
      "minAdaptCoeff     int64\n",
      "name             object\n",
      "probWeight        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load additional configurations\n",
    "print(\"Loading Release and Quality configs...\")\n",
    "with open(DATA_ROOT / 'stock_release.json', 'r', encoding='utf-8') as f:\n",
    "    stock_release_config = json.load(f)\n",
    "\n",
    "with open(DATA_ROOT / 'fish_release.json', 'r', encoding='utf-8') as f:\n",
    "    fish_release_config = json.load(f)\n",
    "\n",
    "with open(DATA_ROOT / 'basic_fish_quality.json', 'r', encoding='utf-8') as f:\n",
    "    basic_fish_quality_config = json.load(f)\n",
    "print(\"Configs loaded.\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# 'related_ponds' should be available from the previous cell execution\n",
    "# If not, we rely on the logic that this cell is run after Cell 5.\n",
    "if 'related_ponds' not in locals():\n",
    "    print(\"Warning: 'related_ponds' not found. Please ensure the previous cell is executed.\")\n",
    "    unique_stock_ids = set()\n",
    "else:\n",
    "    unique_stock_ids = set(pond.get('fishStockId') for pond in related_ponds if pond.get('fishStockId'))\n",
    "\n",
    "print(f\"Processing {len(unique_stock_ids)} unique Stock IDs associated with the current map.\")\n",
    "\n",
    "for stock_id in unique_stock_ids:\n",
    "    # Find all releases for this stock\n",
    "    # Note: Scanning all values in stock_release_config might be inefficient for very large datasets,\n",
    "    # but acceptable for this precompute scope.\n",
    "    stock_releases = [item for item in stock_release_config.values() if item.get('stockId') == stock_id]\n",
    "    \n",
    "    for sr in stock_releases:\n",
    "        release_id = sr.get('releaseId')\n",
    "        fish_quality_id = sr.get('fishId') # referred as fishId in stock_release.json, but actually qualityId\n",
    "        fish_env_affinity_id = sr.get('fishEnvId') # referred as fishEnvId in stock_release.json\n",
    "        \n",
    "        # Lookup Release Info\n",
    "        release_info = fish_release_config.get(str(release_id))\n",
    "        if not release_info:\n",
    "            # print(f\"Warning: Release ID {release_id} not found in fish_release.json\")\n",
    "            continue\n",
    "            \n",
    "        # Lookup Fish Quality Info\n",
    "        fish_info = basic_fish_quality_config.get(str(fish_quality_id))\n",
    "        species_id = fish_info.get('species', -1) if fish_info else -1\n",
    "            \n",
    "        row = {\n",
    "            'stockId': stock_id,\n",
    "            'releaseId': release_id,\n",
    "            'qualityId': fish_quality_id,\n",
    "            'envAffinityId': fish_env_affinity_id, # Renamed from envId for clarity\n",
    "            'speciesId': species_id,\n",
    "            \n",
    "            # Release Limits\n",
    "            'weight_min': release_info.get('weightMin'),\n",
    "            'weight_max': release_info.get('weightMax'),\n",
    "            'len_min': release_info.get('lengthMin'),\n",
    "            'len_max': release_info.get('lengthMax'),\n",
    "\n",
    "            # Environment Coefficients (Added per request)\n",
    "            'minEnvCoeff': release_info.get('minEnvCoeff', 0),\n",
    "            'minAdaptCoeff': release_info.get('minAdaptCoeff', 0),\n",
    "            \n",
    "            # Debug/Display info\n",
    "            'name': release_info.get('name'),\n",
    "            'probWeight': release_info.get('probWeightIdeal')\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "stockFishesPd = pd.DataFrame(rows)\n",
    "print(f\"Created stockFishesPd with {len(stockFishesPd)} rows.\")\n",
    "if not stockFishesPd.empty:\n",
    "    print(stockFishesPd.head().to_string())\n",
    "    print(\"\\nColumn Types:\")\n",
    "    print(stockFishesPd.dtypes)\n",
    "else:\n",
    "    print(\"DataFrame is empty. Check if stock_release.json maps correctly to the pond stock IDs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87e08507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 继续进行后续数据关联 (Data Enrichment Phase II)\n",
    "\n",
    "# 8. 环境亲和性关联 (Environment Affinity Lookup):\n",
    "#    - 目标: 丰富鱼类的环境适应参数。\n",
    "#    - 操作: 使用 `envAffinityId` (原 `fishEnvId`) 关联 `fish_env_affinity.json`。\n",
    "#    - 提取关键属性 (Attributes Extraction):\n",
    "#         - 基础ID关联: structId (结构), tempId (温度), layerId (水层), lightId (光照)。\n",
    "#         - 诱鱼系数: baitCoeffGroup, baitTypeCoeffGroup, periodCoeffGroup (时段)。\n",
    "#         - 适应性参数: \n",
    "#             - pressureSensitivity (气压敏感度)\n",
    "#             - minAdaptLureRatio / maxAdaptLureRatio (路亚适应比例)\n",
    "#             - maxAcceptLengthRatio (最大接受长度比)\n",
    "#         - 衰减配置: underLengthDecayCoeff / overLengthDecayCoeff (体型偏离衰减)。\n",
    "\n",
    "# 9. 结构体亲和性级联查找 (Structure Affinity Cascade):\n",
    "#    - 目标: 获取具体的物理结构交互参数。\n",
    "#    - 操作: 使用步骤 8 获得的 `structId`，查询 `struct_affinity.json`。\n",
    "#    - 提取参数 (Parameters Extraction): \n",
    "#         - `List`: 包含 `structType` (结构类型) 和 `coeff` (系数) 的列表。\n",
    "\n",
    "# 10. 温度亲和性级联查找 (Temperature Affinity Cascade):\n",
    "#    - 目标: 获取鱼类对温度的敏感度配置。\n",
    "#    - 操作: 使用步骤 8 获得的 `tempId`，查询 `temp_affinity.json`。\n",
    "#    - 提取参数 (Parameters Extraction): \n",
    "#         - `temperatureFav`: 最适温度 (注意可能需要缩放，如 220 -> 22.0)。\n",
    "#         - `tempAffectedRatio`: 温度影响比率。\n",
    "#         - `tempThreshold`: 温度容忍阈值。\n",
    "\n",
    "# 11. 水层亲和性级联查找 (Water Layer Affinity Cascade):\n",
    "#    - 目标: 获取鱼类在不同水层的分布偏好。\n",
    "#    - 操作: 使用步骤 8 获得的 `layerId`，查询 `water_layer_affinity.json`。\n",
    "#    - 提取参数 (Parameters Extraction): \n",
    "#         - `List`: 包含 `layerType` (水层类型, 如上/中/下) 和 `coeff` (系数) 的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992238dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Affinity Configs...\n",
      "Affinity Configs loaded.\n",
      "Enriching DataFrame...\n",
      "Enrichment Complete.\n",
      "New DataFrame Shape: (35, 31)\n",
      "   qualityId  envAffinityId  temperatureFav  structId   tempId                                                                                   layerList\n",
      "0  101034430        1013390             195   2011030  2021010  [{'layerType': 1, 'coeff': 1}, {'layerType': 2, 'coeff': 1}, {'layerType': 3, 'coeff': 1}]\n",
      "1  101034090        1013050             195   2010940  2020920  [{'layerType': 1, 'coeff': 1}, {'layerType': 2, 'coeff': 1}, {'layerType': 3, 'coeff': 1}]\n",
      "2  101031007        1010066             195   2010940  2020920  [{'layerType': 1, 'coeff': 1}, {'layerType': 2, 'coeff': 1}, {'layerType': 3, 'coeff': 1}]\n",
      "3  101034450        1013410             195   2011040  2021020  [{'layerType': 1, 'coeff': 1}, {'layerType': 2, 'coeff': 1}, {'layerType': 3, 'coeff': 1}]\n",
      "4  101034510        1013470             220   2011060  2021040  [{'layerType': 1, 'coeff': 1}, {'layerType': 2, 'coeff': 1}, {'layerType': 3, 'coeff': 1}]\n"
     ]
    }
   ],
   "source": [
    "# 9-11. 实现环境与亲和性级联查找 (Env & Affinity Cascade Lookup)\n",
    "\n",
    "print(\"Loading Affinity Configs...\")\n",
    "# 1. 加载所有亲和性配置 (Load Configs)\n",
    "with open(DATA_ROOT / 'fish_env_affinity.json', 'r', encoding='utf-8') as f:\n",
    "    env_affinity_config = json.load(f)\n",
    "\n",
    "with open(DATA_ROOT / 'struct_affinity.json', 'r', encoding='utf-8') as f:\n",
    "    struct_affinity_config = json.load(f)\n",
    "\n",
    "with open(DATA_ROOT / 'temp_affinity.json', 'r', encoding='utf-8') as f:\n",
    "    temp_affinity_config = json.load(f)\n",
    "\n",
    "with open(DATA_ROOT / 'water_layer_affinity.json', 'r', encoding='utf-8') as f:\n",
    "    layer_affinity_config = json.load(f)\n",
    "print(\"Affinity Configs loaded.\")\n",
    "\n",
    "# 2. 准备查找字典 (Prepare Lookup Dicts)\n",
    "#    优化: 直接构建 id -> data 的快速查找字典，避免每次遍历 list\n",
    "#    注意: JSON key通常是字符串, DataFrame中Id可能是int, 查找时需注意类型转换\n",
    "\n",
    "def get_config_by_id(config_dict, target_id):\n",
    "    \"\"\"Safe lookup helper handling str/int key mismatch\"\"\"\n",
    "    if target_id is None:\n",
    "        return None\n",
    "    return config_dict.get(str(target_id))\n",
    "\n",
    "# 3. 扩展 DataFrame (Enrich DataFrame)\n",
    "#    虽然可以使用 apply，但在列数较多且逻辑复杂时，迭代或列表推导式便于调试和错误处理\n",
    "#    考虑到数据量不大 (几十到几百行)，直接遍历 row 更新字典列表然后重新创建 DF 也是一种清晰的方法\n",
    "#    或者使用 apply + Series expand\n",
    "\n",
    "def enrich_row(row):\n",
    "    # Step 8: Env Affinity Lookup\n",
    "    env_id = row.get('envAffinityId')\n",
    "    env_info = get_config_by_id(env_affinity_config, env_id)\n",
    "    \n",
    "    extra_data = {}\n",
    "    \n",
    "    if env_info:\n",
    "        # Extract basic Env IDs\n",
    "        struct_id = env_info.get('structId')\n",
    "        temp_id = env_info.get('tempId')\n",
    "        layer_id = env_info.get('layerId')\n",
    "        light_id = env_info.get('lightId')\n",
    "        \n",
    "        extra_data.update({\n",
    "            'structId': struct_id,\n",
    "            'tempId': temp_id,\n",
    "            'layerId': layer_id,\n",
    "            'lightId': light_id,\n",
    "            # Coeffs\n",
    "            'baitCoeffGroup': env_info.get('baitCoeffGroup'),\n",
    "            'baitTypeCoeffGroup': env_info.get('baitTypeCoeffGroup'),\n",
    "            'periodCoeffGroup': env_info.get('periodCoeffGroup'),\n",
    "            # Adaptability Stats\n",
    "            'pressureSensitivity': env_info.get('pressureSensitivity'),\n",
    "            'minAdaptLureRatio': env_info.get('minAdaptLureRatio'),\n",
    "            'maxAdaptLureRatio': env_info.get('maxAdaptLureRatio'),\n",
    "            'maxAcceptLengthRatio': env_info.get('maxAcceptLengthRatio'),\n",
    "            'underLengthDecayCoeff': env_info.get('underLengthDecayCoeff'),\n",
    "            'overLengthDecayCoeff': env_info.get('overLengthDecayCoeff'),\n",
    "        })\n",
    "        \n",
    "        # Step 9: Structure Affinity Cascade\n",
    "        struct_info = get_config_by_id(struct_affinity_config, struct_id)\n",
    "        if struct_info:\n",
    "            extra_data['structList'] = struct_info.get('List') # raw list of {structType, coeff}\n",
    "        \n",
    "        # Step 10: Temperature Affinity Cascade\n",
    "        temp_info = get_config_by_id(temp_affinity_config, temp_id)\n",
    "        if temp_info:\n",
    "            extra_data['temperatureFav'] = temp_info.get('temperatureFav')\n",
    "            extra_data['tempAffectedRatio'] = temp_info.get('tempAffectedRatio')\n",
    "            extra_data['tempThreshold'] = temp_info.get('tempThreshold')\n",
    "            \n",
    "        # Step 11: Water Layer Affinity Cascade\n",
    "        layer_info = get_config_by_id(layer_affinity_config, layer_id)\n",
    "        if layer_info:\n",
    "            extra_data['layerList'] = layer_info.get('List') # raw list of {layerType, coeff}\n",
    "            \n",
    "    return pd.Series(extra_data)\n",
    "\n",
    "# 应用扩展逻辑\n",
    "print(\"Enriching DataFrame...\")\n",
    "if not stockFishesPd.empty:\n",
    "    enriched_columns = stockFishesPd.apply(enrich_row, axis=1)\n",
    "    \n",
    "    # Concatenate original df with new columns\n",
    "    stockFishesPd = pd.concat([stockFishesPd, enriched_columns], axis=1)\n",
    "    \n",
    "    print(\"Enrichment Complete.\")\n",
    "    print(f\"New DataFrame Shape: {stockFishesPd.shape}\")\n",
    "    print(stockFishesPd[['qualityId','envAffinityId','temperatureFav', 'structId', 'tempId', 'layerList']].head().to_string())\n",
    "else:\n",
    "    print(\"stockFishesPd is empty, skipping enrichment.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
